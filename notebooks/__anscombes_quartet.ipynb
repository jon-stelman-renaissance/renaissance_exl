{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "991b7e42",
   "metadata": {},
   "source": [
    "# Anscombe's Quartet\n",
    "_Renaissance EXL_  \n",
    "_Renaissance Learning, 2023_  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02bbf56",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a82896",
   "metadata": {},
   "source": [
    "When first learning about statistics, it can be enticing to think that **quantitative descriptive statistics** like *mean*, *standard deviation*, and the *correlation coefficient* tell us all we need to know about the data. Graphing data, on the other hand, may be seen as subjective when compared with statistics. A graph might suggest a general shape, but a standard deviation is precise.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e32899",
   "metadata": {},
   "source": [
    "As we'll see, good data analysis requires *both* statistical analysis *and* data visualization. Neither method is complete on its own, and we need information from both methods in order to make sound data-driven decisions.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d82d01e5",
   "metadata": {},
   "source": [
    "In 1973, the English statistician **Frank Anscombe**, who was a strong advocate for this balanced approach, published four sets of data to make the point very clear. We'll load these datasets, known as *Anscombe's Quartet*, and let the data do the talking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42aee87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece1539d",
   "metadata": {},
   "source": [
    "## View Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f104041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data from a CSV file\n",
    "anscombe = pd.read_csv('../data/anscombes_quartet.csv')\n",
    "\n",
    "display(anscombe.head(10))\n",
    "print(len(anscombe), 'rows')\n",
    "print(anscombe['quartet'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72da6e5a",
   "metadata": {},
   "source": [
    "Taking a look, we see that the DataFrame has three columns. All four quartets are included in the frame, and the set to which the data belongs is labeled by the `quartet` column. The values in this column are of type `string`, capitalized Roman numerals representing each dataset.  \n",
    "  \n",
    "If we're the kind of person who thinks we're really clever, we should be able to just display the data and understand it well enough. Let's give it a go..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a62c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "quartets = ['I', 'II', 'III', 'IV']\n",
    "\n",
    "for q in quartets:\n",
    "    print(\"\\nAscombe's Quartet {}\".format(q))\n",
    "    qdata = anscombe[anscombe.quartet == q].reset_index(drop=True)\n",
    "    display(qdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5a829a",
   "metadata": {},
   "source": [
    "Personally, figuring out what each dataset looks like, and describing its variance, correlation and average in my head is too much work for me. Let's code instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e26354",
   "metadata": {},
   "source": [
    "## Summary Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49662df0",
   "metadata": {},
   "source": [
    "Let's print out some pretty common descriptive statistics:\n",
    "- Mean ($μ$)\n",
    "- Median ($Mdn$)\n",
    "- Standard Deviation ($σ$)\n",
    "- Pearson Correlation Coefficient ($r$)\n",
    "- Linear regression line ($y = mx + b$)\n",
    "    \n",
    "Note: We can change the rounding precision by updating the `precision` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc9d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = 2\n",
    "\n",
    "datasets = {}\n",
    "for q in quartets:\n",
    "    qdata = anscombe[anscombe.quartet == q]\n",
    "    x = qdata['x'].to_list()\n",
    "    y = qdata['y'].to_list()\n",
    "    m, b = np.polyfit(x, y, deg=1)  # slope, intercept\n",
    "    m = round(m, precision)\n",
    "    b = round(b, precision)\n",
    "    \n",
    "    # Add to dictionary for easier plotting later\n",
    "    datasets[q] = {'x': x, 'y': y}\n",
    "    \n",
    "    # Print summary statistics\n",
    "    print(q)\n",
    "    print('            Mdn of x:  ', round(np.median(x), precision))\n",
    "    print('              μ of x:  ', round(np.mean(x), precision))\n",
    "    print('              σ of x:  ', round(np.std(x), precision))\n",
    "    print('              μ of y:  ', round(np.mean(y), precision))\n",
    "    print('              σ of y:  ', round(np.std(y), precision))\n",
    "    print('              r(x~y):  ', round(np.corrcoef(x, y)[0][1], precision))\n",
    "    print('    Linear reg. line:  ', f'y = {round(m, precision)} x + {round(b, precision)}', '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9db5829",
   "metadata": {},
   "source": [
    "Perhaps surprisingly, these four data sets have remarkably similar statistics! Aside from their median $x$ values differing slightly, all other statistics are identical to the nearest hundredth. So the data must be pretty similar, right? Let's visualize it, just to check..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ae6b1",
   "metadata": {},
   "source": [
    "## Plot Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2761b29d",
   "metadata": {},
   "source": [
    "The code cell below will create and display scatter plots for each of the four quartets. It makes use of the plotting library `matplotlib`, which we imported earlier. Don't worry if you don't understand the plotting code yet – we'll take a closer look at plotting in the next tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9559a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from https://matplotlib.org/stable/gallery/specialty_plots/anscombe.html\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(10, 10),\n",
    "                        sharex=True,\n",
    "                        sharey=True, \n",
    "                        gridspec_kw={'wspace': 0.08, 'hspace': 0.08})\n",
    "\n",
    "axs[0, 0].set(xlim=(0, 20), ylim=(2, 14))\n",
    "axs[0, 0].set(xticks=range(0, 21, 5), yticks=range(4, 13, 4))\n",
    "\n",
    "blue = '#005793'\n",
    "green = '#78C42A'\n",
    "grey = '#F3F5F7'\n",
    "\n",
    "i = 0\n",
    "for label, values in datasets.items():\n",
    "    x = values['x']\n",
    "    y = values['y']\n",
    "    ax = axs.flat[i]\n",
    "    \n",
    "    ax.text(0.1, 0.9, label, fontsize=16, transform=ax.transAxes, va='top')\n",
    "    ax.tick_params(direction='in', top=True, right=True)\n",
    "    ax.plot(x, y, 'o', color=blue)\n",
    "\n",
    "    # draw linear regression line\n",
    "    p1, p0 = np.polyfit(x, y, deg=1)  # slope, intercept\n",
    "    ax.axline(xy1=(0, p0), slope=p1, color=green, lw=2)\n",
    "\n",
    "    # add text box for the statistics\n",
    "    stats = (f'$\\\\mu$ = {np.mean(y):.2f}\\n'\n",
    "             f'$\\\\sigma$ = {np.std(y):.2f}\\n'\n",
    "             f'$r$ = {np.corrcoef(x, y)[0][1]:.2f}')\n",
    "    bbox = dict(boxstyle='round', fc=grey, ec=grey, alpha=0.5)\n",
    "    ax.text(0.95, 0.07, stats, fontsize=12, bbox=bbox,\n",
    "            transform=ax.transAxes, horizontalalignment='right')\n",
    "    i += 1\n",
    "plt.suptitle(\"Anscombe's Quartet\", fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39134f8",
   "metadata": {},
   "source": [
    "Ok, obviously these data sets are not at all similar. Now that we've visualized the data, we might make the following assertions:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c1ea21",
   "metadata": {},
   "source": [
    "- **Quartet I:** Well correlated, linear, increasing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391bc0d8",
   "metadata": {},
   "source": [
    "- **Quartet II:** Quadratic function, concave down, $y$ is decreasing as $x$ increases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88638ed4",
   "metadata": {},
   "source": [
    "- **Quartet III:** Highly correlated, linear increasing with one obvious outlier point that decreases the correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eca8451",
   "metadata": {},
   "source": [
    "- **Quartet IV:** Zero correlation, with points dispersed along a single $x$ value, with one outlier point that is responsible for the positive correlation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f32e6c",
   "metadata": {},
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1ee897",
   "metadata": {},
   "source": [
    "Despite being more qualitative, these visual representations of the data are extremely important for how we think about the data. This new knowledge doesn't necessarily nullify the summary statistics calculated earlier, *but it might*. The difference between Quartets I and II highlights that we should be careful about projections we might make. Just because the correlation is positive and the linear regression provides a positive slope does not mean that we should predict that the values will increase.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52d9a7",
   "metadata": {},
   "source": [
    "Similarly, when looking at Quartets III and IV, we should notice the important contributions of just one outlier in our statistics. Outliers can be the difference between a perfect correlation ($r = 1$) and no relationship ($r = 0$). Any decisions we make or actions we take based on the data should consider these outliers, and whether or not they are an important part of the data's story."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
